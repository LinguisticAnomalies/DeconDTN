{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad0fea88-b647-4387-91ae-70be03040b77",
   "metadata": {},
   "source": [
    "This notebook contains preliminary results using BERT base model on CORAAL dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab0b8b2-f368-4d5c-946f-e779996c0ec8",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "805e9dca-7d1e-4997-90ec-150b5a986c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dddbc62f-cbf5-4e58-b2fa-75cbe652cb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "177ffc17-836c-4117-b06f-1d69f219bade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a65666bc-aaa2-4d72-812f-e1c7790845d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b146d5c7-e443-483a-86d8-f7701e759b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import compute_metrics, compute_metrics_mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4797cff-56bd-4761-8de3-149ee4de4b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5ae4ec2-a3ae-4000-8c5d-86e8169c1d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83866c52-748d-4367-b74e-97efd242a6da",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f000e786-d79d-4c8b-b69f-dd1286431f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv('../data/coraal/processed_coraal.tsv', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22635f37-0fbc-4a5e-83e0-0f8429b66a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "genders = dat.index.to_series().str.split(pat = '_', expand = True).iloc[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eda34661-9b8e-4dd5-976e-aec764940ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.concat([dat, genders], axis = 1).rename(columns= {3:'gender'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dc82bfc-373d-4d8d-87a8-8c527b549113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>location</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DCA_se1_ag1_f_01_1</th>\n",
       "      <td>My-My name is /RD-NAME-6/.One two three four f...</td>\n",
       "      <td>DCA</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCA_se1_ag2_f_01_1</th>\n",
       "      <td>Baseball (laughing), marbles, you know. Uh, Ma...</td>\n",
       "      <td>DCA</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCA_se1_ag1_f_03_1</th>\n",
       "      <td>Um, baseball, football, basketball, tennis, ki...</td>\n",
       "      <td>DCA</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCA_se2_ag1_f_07_1</th>\n",
       "      <td>Mm, /let me see/. Do you want me to answer tha...</td>\n",
       "      <td>DCA</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCA_se3_ag1_f_03_1</th>\n",
       "      <td>I play hopscotch and kickball and sometimes we...</td>\n",
       "      <td>DCA</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 text  \\\n",
       "DCA_se1_ag1_f_01_1  My-My name is /RD-NAME-6/.One two three four f...   \n",
       "DCA_se1_ag2_f_01_1  Baseball (laughing), marbles, you know. Uh, Ma...   \n",
       "DCA_se1_ag1_f_03_1  Um, baseball, football, basketball, tennis, ki...   \n",
       "DCA_se2_ag1_f_07_1  Mm, /let me see/. Do you want me to answer tha...   \n",
       "DCA_se3_ag1_f_03_1  I play hopscotch and kickball and sometimes we...   \n",
       "\n",
       "                   location gender  \n",
       "DCA_se1_ag1_f_01_1      DCA      f  \n",
       "DCA_se1_ag2_f_01_1      DCA      f  \n",
       "DCA_se1_ag1_f_03_1      DCA      f  \n",
       "DCA_se2_ag1_f_07_1      DCA      f  \n",
       "DCA_se3_ag1_f_03_1      DCA      f  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3aff85f5-33af-46f5-aadd-2f5d3bf56d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['pr_text'] = dat.text.apply(lambda x: preprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e307abd6-f9d8-4e59-a85a-2523644d01e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"my-my name is /rd-name-6/.one two three four five six seven eight nine ten.at home?i play uh, football, jump rope, that's all. we play double dutch.s- you have to uh- two people have- two people have to turn the rope.and you jump in the rope and start to jumping. no.yes.hide and seek.person gotta uh, count to twenty, and while the um, some more children hide, you got try to find 'em.i don't know. you sposta uh, say something like, i- uh- everybody put your feet in and somebody say they- they gonna be the namer and then you say b- something like uh, uh- say i forgot.mm-hm.i play d- i have- i have some /boxes/ games at home.don't spill the bean and i have a puzzle.and i have a game called /ergonaut/.it got some marbles with it and four dices and you sposta roll u- roll the dice and have some holes in it. and you- wherever you- where the dice stop at you sposta put the uh, marbles in the hole.you- it have four things down the row and then you get all four of your marbles down there, you won.[no.]yes.no.some friends of mines, live on- over top of me.have to get a ball and then some- some children be on one team and some be on another- on another team. and then somebody roll the ball and then you sposta kick it and run to a base.whoev- you- if- if you uh, hit the person before they get on base, they out. and the one who get the most points win. no.[ ] no.[i-]nobody.no.yes. i watch- in the morning i get up. i watch baby daphne, cartoon castle,and i watch uh, mister ed, the flintstone, and /mahale's-/ mchale's navyand my favorite martian. mm-mm.[yes.]it's about all c- she showed cartoons.uh, one of 'em was uh, popeye.uh, so this uh, submarine came. he was in the navy,andthey saw a submarine. they start fighting, and popeye, he ate some spinach and he took and went to the water and fight the su- submarine with some- a j- jap was in it.[th-]uh-huh.yes.read- uh, i have a book at school called uh, above the cloudsand i r- read uh, m- /along friendly roads/. adventures.i r- uh, one of 'em- in one of the books it's about uh, this uh- this lady, she went to the railroad station and got this /austrian/. well he- he was in the circus, but this- was no more circus so the lady took him, and she took him to the store. and he took and ate the man uh, watch.they try to get it out his mouth.and then they went home. that's all.yes.i had a uh, dog before. no a cat before.he got caught- he got caught up in a uh- we went to playground. he followed us. he got caught up in a fence.and then i had a dog before.his name was blackie.and he was scared to go out in the front so my father took him to the dog pound.nothing, [somebody] came and got him.every time we try to take him out front, he wouldn't come out front./rd-school-2/. it has another pre-school on the other side of it. v- math, history, um, reading, um, science, spelling, we- i study a lot. readingand math.yes.her name is uh, miss /rd-name-2/.she- every time you be bad, she'll holler at you. if you don't quiet, she have a big stick, and she'll hit you with it.[no.]sometime some of 'em stay at school and play on the merry-go-round, some of us go home. go home.no.stay in the house and cook.she nice.her name mrs. /rd-name-2/.uh, she don't holler at you.she give you- she don't give you too much work to do.she let you draw. and some- if you had go bathroom, you ask, and she'll let you go.no.no.no, they play some on the children. they take a uh- a pin- a safety pin, and put some paper over and stick it in- stick it in somebody chair. when they sit down they start to hollering.yes. no.yes.one of 'em name uh, /rd-name-2/, /rd-name-2/, um, /rd-name-3/ and um, the- a girl, her mother named her /rd-name-1/. all we do is play jump rope.no. oh, we play tag.some- somebody have to- like we play tag and somebody- last one who run to a tree is it.and then, somebody- everybody'll get off base and whoever they touch- whoever the p- p- person that it touch somebody else, that person that they touch is it.no.[<clears throat>]no.i don't know.we ask if she wanna play. she say yes.yes.i don't know what i wanna be.no.i keep thinking i wanna be a lot of things.work in a s- work in a safeway.uh, be a nurse.mm, work in a- uh, be a secretary.that's all. go through college. i- i would take, i would go downtown and buy me some shoes and some clothes to wear. i'd go to the store and buy some food.huh?bread, meatloaf, chicken, ham, uh, cup- uh, popcorn, sausage, and bacon,liver,uh, hot dog, [ha-]sweet peas,uh, cabbage,carrot. yeah.sometimes i- sometime i help my mama cook.s- and sometime i uh, cl- clean- uh, sweep the floor.wash the dishes.mop the floor.no.no. go downtown and buy some fireworks.go and visit peoples. um, go far.go and see my sister.no. [yes.]no. all we do is dress up and go out for trick or treat.gypsy,old woman,hobo.i was dressed up as hips- hippie.gypsy. i went to a party.it ain't nothing to tell about.[no.]oh it was /dancing/. a lady brought some of her make up there. case if we ain't had none on us, we could put some on us.we went up on up on the stage and show people our costumes. sh- see who had the best costume. i don't know.no.[yes.]cupcake, um, apple juice, and some candyand apples.no.yes.camel walk,boogaloo,uh, uh, popcorn.at home.sometime i be with uh, a little girl live upstairs from me name /rd-name-4/.no. yes.i dreamed about we was over my uh, father mother house, and then we was moving. and then we- we went past this ghost town, and i fell. i was on the back of the truck, and i /felled/ off it into this ghost house, and the ghost'll come up the steps and i was tryna walk. i couldn't hardly walk. and i got scared.i was glad.[yeah.]no.i think just superstition.[mm-hm.]like they say, you break a mirror, you have bad luck. and the say if you walk on- around a pole, you'll have /baddy/ luck, and if you walk under a ladder, you'll have bad luck.not that i know of.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['pr_text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c3e7da0-bfe3-4462-bdf4-b5a288ae80e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_109114/2061932604.py:3: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  dat.location_num = dat.location.replace({'DCA': 0, 'VLD': 1, 'DCB': 2, 'PRV': 3, 'LES': 4, 'ROC': 5, 'ATL': 6})\n"
     ]
    }
   ],
   "source": [
    "#recode gender\n",
    "dat.gender.replace({'f': 0, 'm': 1}, inplace=True)\n",
    "dat.location_num = dat.location.replace({'DCA': 0, 'VLD': 1, 'DCB': 2, 'PRV': 3, 'LES': 4, 'ROC': 5, 'ATL': 6})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a41572e-9ee1-4baa-9d65-70ebb90de692",
   "metadata": {},
   "source": [
    "### Train on whole CORAAL corpus to classify M vs F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc69426-467d-49f1-a84f-b96599e82390",
   "metadata": {},
   "source": [
    "- data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54382eb5-5620-4f21-93e4-757362be5d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74e1064-260d-47e0-acd6-8b9f549f540e",
   "metadata": {},
   "source": [
    "- Gender distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c630b813-3b0a-4062-b2bf-1c11096fac4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(dat.gender.value_counts()/len(dat)).plot.bar()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13427a07-5b59-4341-8f61-2934359ea280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subdat.groupby(['gender','location']).size().plot.bar(figsize = (8,8))\n",
    "#pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78708888-c252-4460-9a96-7f2c0701d7e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Split training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66ef77cf-aa85-4725-ae82-0f65c43731bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2022\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9554656e-b30a-4fae-a9c5-87dad21924f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9137796a-e79e-4b47-bd93-f97d5a853f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dat['pr_text'].to_list(), dat['gender'].to_list(), test_size = 0.2, random_state=2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52388ce0-29f2-4156-830b-5b98af7de17b",
   "metadata": {},
   "source": [
    "#### Load BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95b94ae2-09d4-490c-b086-c9b9596c9f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "max_length = 256\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name, do_lower_case=True)\n",
    "train_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=max_length, return_tensors='pt')\n",
    "test_encodings = tokenizer(X_test, truncation=True, padding=True, max_length=max_length,return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "381f25d4-12a1-4f43-a0e7-2cfcc85ff0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert our tokenized data into a torch Dataset\n",
    "train_dataset = utils.CoRAALDataSet(train_encodings, y_train)\n",
    "test_dataset = utils.CoRAALDataSet(test_encodings, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1044dcac-151f-4db9-b1a6-560c2f200a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = dat['gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e44087fc-7636-473d-a72a-d77db2dae7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8dcece88-e140-43e1-9a0b-df6d00a824ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results-base',          # output directory\n",
    "    num_train_epochs= 10,              # total number of training epochs\n",
    "    per_device_train_batch_size= 1,  # batch size per device during training\n",
    "    per_device_eval_batch_size= 1,   # batch size for evaluation\n",
    "    warmup_steps=200,                # number of warmup steps for learning rate scheduler\n",
    "    learning_rate=1e-10,\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs-base',            # directory for storing logs\n",
    "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
    "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "    logging_steps=50,               # log & save weights each logging_steps\n",
    "    save_steps=50,\n",
    "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
    "    seed= 2022,\n",
    "    data_seed=2022\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0bc852f4-fdfb-4773-b069-9203b90a5959",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=test_dataset,          # evaluation dataset\n",
    "    compute_metrics=compute_metrics,   # the callback that computes metrics of interest\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7fd955a-3fea-4b2c-ac42-542a27ca797f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sheng136/miniconda3/envs/deDTN/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 184\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1840\n",
      "  Number of trainable parameters = 109483778\n",
      "/home/sheng136/workspace/deDTN/code/utils.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='1840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 350/1840 00:51 < 03:39, 6.78 it/s, Epoch 1/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.723900</td>\n",
       "      <td>0.727424</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.690200</td>\n",
       "      <td>0.727424</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.727200</td>\n",
       "      <td>0.727424</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.687600</td>\n",
       "      <td>0.727424</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.739100</td>\n",
       "      <td>0.727424</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.706000</td>\n",
       "      <td>0.727424</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.737700</td>\n",
       "      <td>0.727424</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 47\n",
      "  Batch size = 1\n",
      "/home/sheng136/miniconda3/envs/deDTN/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./results-base/checkpoint-50\n",
      "Configuration saved in ./results-base/checkpoint-50/config.json\n",
      "Model weights saved in ./results-base/checkpoint-50/pytorch_model.bin\n",
      "/home/sheng136/workspace/deDTN/code/utils.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 47\n",
      "  Batch size = 1\n",
      "/home/sheng136/miniconda3/envs/deDTN/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./results-base/checkpoint-100\n",
      "Configuration saved in ./results-base/checkpoint-100/config.json\n",
      "Model weights saved in ./results-base/checkpoint-100/pytorch_model.bin\n",
      "/home/sheng136/workspace/deDTN/code/utils.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 47\n",
      "  Batch size = 1\n",
      "/home/sheng136/miniconda3/envs/deDTN/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./results-base/checkpoint-150\n",
      "Configuration saved in ./results-base/checkpoint-150/config.json\n",
      "Model weights saved in ./results-base/checkpoint-150/pytorch_model.bin\n",
      "/home/sheng136/workspace/deDTN/code/utils.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 47\n",
      "  Batch size = 1\n",
      "/home/sheng136/miniconda3/envs/deDTN/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./results-base/checkpoint-200\n",
      "Configuration saved in ./results-base/checkpoint-200/config.json\n",
      "Model weights saved in ./results-base/checkpoint-200/pytorch_model.bin\n",
      "/home/sheng136/workspace/deDTN/code/utils.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 47\n",
      "  Batch size = 1\n",
      "/home/sheng136/miniconda3/envs/deDTN/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./results-base/checkpoint-250\n",
      "Configuration saved in ./results-base/checkpoint-250/config.json\n",
      "Model weights saved in ./results-base/checkpoint-250/pytorch_model.bin\n",
      "/home/sheng136/workspace/deDTN/code/utils.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 47\n",
      "  Batch size = 1\n",
      "/home/sheng136/miniconda3/envs/deDTN/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./results-base/checkpoint-300\n",
      "Configuration saved in ./results-base/checkpoint-300/config.json\n",
      "Model weights saved in ./results-base/checkpoint-300/pytorch_model.bin\n",
      "/home/sheng136/workspace/deDTN/code/utils.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 47\n",
      "  Batch size = 1\n",
      "/home/sheng136/miniconda3/envs/deDTN/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./results-base/checkpoint-350\n",
      "Configuration saved in ./results-base/checkpoint-350/config.json\n",
      "Model weights saved in ./results-base/checkpoint-350/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results-base/checkpoint-100 (score: 0.7274243831634521).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=350, training_loss=0.7159529549734933, metrics={'train_runtime': 52.257, 'train_samples_per_second': 35.211, 'train_steps_per_second': 35.211, 'total_flos': 46044434688000.0, 'train_loss': 0.7159529549734933, 'epoch': 1.9})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35efef7-2c0b-4cbb-8ee2-81930793e4eb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Testing other existing methods\n",
    "- load amazon_bert\n",
    "- load stackover_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6004bcc2-8878-44ad-b02f-efa1f0094579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/sheng136/.cache/huggingface/hub/models--bert-base-uncased/snapshots/5546055f03398095e385d7dc625e636cc8910bf2/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/sheng136/.cache/huggingface/hub/models--bert-base-uncased/snapshots/5546055f03398095e385d7dc625e636cc8910bf2/pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_amazon = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(target_names));\n",
    "model_amazon.load_state_dict(torch.load('./models/amazon_bert/pytorch_model.bin'))\n",
    "model_amazon.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ba70ec94-6faf-40c6-ab7f-6c062ae7bd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_amazon.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a37f3fd9-71fe-4df8-b4ec-6418d034ea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model_amazon(**test_encodings)\n",
    "probs = outputs[0].softmax(1)\n",
    "y_preds = probs.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "706ad0d0-7a01-4de8-a775-6e7da10736d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4a93ceb7-875b-4f56-b32a-98627d15875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_acc = evaluate.load('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a00bddee-87bc-4518-8969-c6eb31d35073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.23404255319148937}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_acc.compute(predictions=y_preds, references=test_dataset.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1bbebced-d603-44c0-a675-48843c8aaec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/sheng136/.cache/huggingface/hub/models--bert-base-uncased/snapshots/5546055f03398095e385d7dc625e636cc8910bf2/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/sheng136/.cache/huggingface/hub/models--bert-base-uncased/snapshots/5546055f03398095e385d7dc625e636cc8910bf2/pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_stackover = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(target_names))\n",
    "model_stackover.load_state_dict(torch.load('./models/stackover_bert/pytorch_model.bin'))\n",
    "model_stackover.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c6695174-ef96-43c3-80d4-f8bc5e07dc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model_stackover(**test_encodings)\n",
    "probs = outputs[0].softmax(1)\n",
    "y_preds = probs.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7c6475cd-f094-4755-873c-e674654415b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.40425531914893614}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_acc.compute(predictions=y_preds, references=test_dataset.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624af3ea-6407-49c4-9361-7dd053c39f17",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "93630350-525f-432e-a8dc-26569b281528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.svm import SVC\n",
    "ik\n",
    "sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848a0d3b-dbfa-4d0d-9d92-8d7f19fd4168",
   "metadata": {},
   "source": [
    "- Considering limited data size, use K-Fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a2437869-6a99-4105-883f-76b5edd6d6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dat['pr_text'].to_list(), dat['gender'].to_list(), test_size = 0.2, random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9f4bdb2e-70e3-402c-8ded-85351f0f1007",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfvec = TfidfVectorizer(ngram_range=(1,2),max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ee7a3748-1e3d-43b5-859b-4fb4e49d4a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train = tfvec.fit_transform(X_train)\n",
    "tfidf_test = tfvec.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a6825ee7-e1ad-482e-840a-af1b10d979c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you', 'taking', 'the', 'time', 'out', 'of', 'your', 'busy', 'day']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tfvec.vocabulary_)[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2fcbdc66-e19a-448f-8dd7-dd49837f7a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMclf = SVC(C=10, kernel='linear', degree=3, gamma='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7e10a192-0204-4932-b854-d4d5cb3602fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86 accuracy with a standard deviation of 0.07\n"
     ]
    }
   ],
   "source": [
    "acc = cross_val_score(SVMclf, tfidf_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (acc.mean(), acc.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6874b5ac-7551-4ef8-b64d-4186a5a07e80",
   "metadata": {},
   "source": [
    "- Using C = 10, test set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1d5e85ce-1f89-4ac9-889f-53301439db05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "13448922-69b3-4302-8511-51f3d9636f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5531914893617021"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(C=10, kernel='linear', degree=3, gamma='auto').fit(tfidf_train, y_train)\n",
    "svm_preds = clf.predict(tfidf_test)\n",
    "accuracy_score(y_true=y_test,y_pred = svm_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f454db24-c181-4b98-afc1-4f89478643c1",
   "metadata": {},
   "source": [
    "## Predict provenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc566cbe-873b-4871-bf73-afef371daa7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DCA', 'VLD', 'DCB', 'PRV', 'LES', 'ROC', 'ATL'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.location.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e352d707-caae-4d9d-a2df-b69f5c347259",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['location_num'] = dat.location.replace({'DCA': 0, 'VLD': 1, 'DCB': 2, 'PRV': 3, 'LES': 4, 'ROC': 5, 'ATL': 6},inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d2efa25-2e6c-4a2f-8f48-3484fa26cace",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = dat.location_num.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa808d86-dddd-45cb-b3bb-c05b5945cf75",
   "metadata": {},
   "source": [
    "- Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc7c89bb-b8f4-4137-b3e9-70d311b0646e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    74\n",
       "2    63\n",
       "3    32\n",
       "5    19\n",
       "4    15\n",
       "1    14\n",
       "6    14\n",
       "Name: location, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.location_num.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "801ac7e9-655e-4351-86d2-979c527d016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dat['pr_text'].to_list(), dat['location_num'].to_list(), test_size = 0.2, random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06336769-88bf-486b-9743-fce470e473c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at /home/sheng136/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/vocab.txt\n",
      "loading file tokenizer.json from cache at /home/sheng136/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/sheng136/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/sheng136/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "max_length = 256\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name, do_lower_case=True)\n",
    "train_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=max_length, return_tensors='pt')\n",
    "test_encodings = tokenizer(X_test, truncation=True, padding=True, max_length=max_length,return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9de9719b-83c5-4842-83af-3265f741a248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert our tokenized data into a torch Dataset\n",
    "train_dataset = utils.CoRAALDataSet(train_encodings, y_train)\n",
    "test_dataset = utils.CoRAALDataSet(test_encodings, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "235ce374-55c6-4d44-910e-e17a8b22d190",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/sheng136/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/sheng136/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "33cff171-992e-4e01-92ba-cf0c0f780d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using `logging_steps` to initialize `eval_steps` to 200\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results-provonance',          # output directory\n",
    "    num_train_epochs= 15,              # total number of training epochs\n",
    "    per_device_train_batch_size= 1,  # batch size per device during training\n",
    "    per_device_eval_batch_size= 1,   # batch size for evaluation\n",
    "    warmup_steps=200,                # number of warmup steps for learning rate scheduler\n",
    "    learning_rate=1e-5,\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs-provonance',            # directory for storing logs\n",
    "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
    "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "    logging_steps=200,               # log & save weights each logging_steps\n",
    "    save_steps=200,\n",
    "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
    "    seed=2022,\n",
    "    data_seed=2022\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ecada02e-1470-4949-b718-622961e2f425",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=test_dataset,          # evaluation dataset\n",
    "    compute_metrics=compute_metrics_mult,   # the callback that computes metrics of interest\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "79b6ead2-bc3b-4620-803b-5400ccf7bba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sheng136/miniconda3/envs/deDTN/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 184\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2760\n",
      "  Number of trainable parameters = 109487623\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2600' max='2760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2600/2760 03:10 < 00:11, 13.65 it/s, Epoch 14/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.282900</td>\n",
       "      <td>1.045263</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.680851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.233700</td>\n",
       "      <td>1.123191</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.765957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.989932</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.765957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.077800</td>\n",
       "      <td>1.110522</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.765957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>1.169299</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.723404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>1.059134</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.723404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>1.223259</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.808511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.980133</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.808511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.161932</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.765957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.157656</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.787234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.170780</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.787234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.159461</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.808511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.170412</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.787234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 47\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to ./results-provonance/checkpoint-200\n",
      "Configuration saved in ./results-provonance/checkpoint-200/config.json\n",
      "Model weights saved in ./results-provonance/checkpoint-200/pytorch_model.bin\n",
      "/home/sheng136/workspace/deDTN/code/utils.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 47\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to ./results-provonance/checkpoint-400\n",
      "Configuration saved in ./results-provonance/checkpoint-400/config.json\n",
      "Model weights saved in ./results-provonance/checkpoint-400/pytorch_model.bin\n",
      "/home/sheng136/workspace/deDTN/code/utils.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 47\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to ./results-provonance/checkpoint-600\n",
      "Configuration saved in ./results-provonance/checkpoint-600/config.json\n",
      "Model weights saved in ./results-provonance/checkpoint-600/pytorch_model.bin\n",
      "/home/sheng136/workspace/deDTN/code/utils.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 47\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to ./results-provonance/checkpoint-800\n",
      "Configuration saved in ./results-provonance/checkpoint-800/config.json\n",
      "Model weights saved in ./results-provonance/checkpoint-800/pytorch_model.bin\n",
      "/home/sheng136/workspace/deDTN/code/utils.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 47\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to ./results-provonance/checkpoint-1000\n",
      "Configuration saved in ./results-provonance/checkpoint-1000/config.json\n",
      "Model weights saved in ./results-provonance/checkpoint-1000/pytorch_model.bin\n",
      "/home/sheng136/workspace/deDTN/code/utils.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 47\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to ./results-provonance/checkpoint-1200\n",
      "Configuration saved in ./results-provonance/checkpoint-1200/config.json\n",
      "Model weights saved in ./results-provonance/checkpoint-1200/pytorch_model.bin\n",
      "/home/sheng136/workspace/deDTN/code/utils.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 47\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to ./results-provonance/checkpoint-1400\n",
      "Configuration saved in ./results-provonance/checkpoint-1400/config.json\n",
      "Model weights saved in ./results-provonance/checkpoint-1400/pytorch_model.bin\n",
      "/home/sheng136/workspace/deDTN/code/utils.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 47\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to ./results-provonance/checkpoint-1600\n",
      "Configuration saved in ./results-provonance/checkpoint-1600/config.json\n",
      "Model weights saved in ./results-provonance/checkpoint-1600/pytorch_model.bin\n",
      "/home/sheng136/workspace/deDTN/code/utils.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 47\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to ./results-provonance/checkpoint-1800\n",
      "Configuration saved in ./results-provonance/checkpoint-1800/config.json\n",
      "Model weights saved in ./results-provonance/checkpoint-1800/pytorch_model.bin\n",
      "/home/sheng136/workspace/deDTN/code/utils.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 47\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to ./results-provonance/checkpoint-2000\n",
      "Configuration saved in ./results-provonance/checkpoint-2000/config.json\n",
      "Model weights saved in ./results-provonance/checkpoint-2000/pytorch_model.bin\n",
      "/home/sheng136/workspace/deDTN/code/utils.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 47\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to ./results-provonance/checkpoint-2200\n",
      "Configuration saved in ./results-provonance/checkpoint-2200/config.json\n",
      "Model weights saved in ./results-provonance/checkpoint-2200/pytorch_model.bin\n",
      "/home/sheng136/workspace/deDTN/code/utils.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 47\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to ./results-provonance/checkpoint-2400\n",
      "Configuration saved in ./results-provonance/checkpoint-2400/config.json\n",
      "Model weights saved in ./results-provonance/checkpoint-2400/pytorch_model.bin\n",
      "/home/sheng136/workspace/deDTN/code/utils.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 47\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to ./results-provonance/checkpoint-2600\n",
      "Configuration saved in ./results-provonance/checkpoint-2600/config.json\n",
      "Model weights saved in ./results-provonance/checkpoint-2600/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results-provonance/checkpoint-1600 (score: 0.9801327586174011).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2600, training_loss=0.05925882034576856, metrics={'train_runtime': 190.35, 'train_samples_per_second': 14.5, 'train_steps_per_second': 14.5, 'total_flos': 342059727360000.0, 'train_loss': 0.05925882034576856, 'epoch': 14.13})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e664d8-f89f-4324-8dd5-221a3a83e85b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
