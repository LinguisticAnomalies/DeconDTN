{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98ff9a47-86b8-4e7c-b66d-192f935ea837",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T04:36:50.800890Z",
     "iopub.status.busy": "2023-09-13T04:36:50.800070Z",
     "iopub.status.idle": "2023-09-13T04:36:50.813666Z",
     "shell.execute_reply": "2023-09-13T04:36:50.812184Z",
     "shell.execute_reply.started": "2023-09-13T04:36:50.800825Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "import itertools\n",
    "from tqdm.auto import tqdm\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "import datasets\n",
    "from contextlib import nullcontext\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import (\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    LlamaTokenizer,\n",
    "    LlamaForSequenceClassification,\n",
    "    TrainerCallback,\n",
    "    default_data_collator,\n",
    ")\n",
    "from peft import (\n",
    "        PeftConfig,\n",
    "        PeftModel,\n",
    "        get_peft_model,\n",
    "        LoraConfig,\n",
    "        TaskType,\n",
    "        prepare_model_for_int8_training,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01cd04e0-d992-430e-9a13-8e9b65a2a892",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T04:30:47.757346Z",
     "iopub.status.busy": "2023-09-13T04:30:47.756210Z",
     "iopub.status.idle": "2023-09-13T04:30:47.771295Z",
     "shell.execute_reply": "2023-09-13T04:30:47.769560Z",
     "shell.execute_reply.started": "2023-09-13T04:30:47.757273Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class train_config:\n",
    "    def __init__(self):\n",
    "        self.quantization: bool = False\n",
    "\n",
    "    \n",
    "globalconfig = train_config()\n",
    "globalconfig.quantization = True\n",
    "globalconfig.device = \"cuda:0\"\n",
    "globalconfig.profiler = False\n",
    "globalconfig.output_dir = f\"/bime-munin/xiruod/tmp/quantization_epoch3-llama-output-1244/\"\n",
    "globalconfig.model_id = \"/bime-munin/llama2_hf/llama-2-7b_hf/\"\n",
    "globalconfig.max_seq_length = 1024\n",
    "globalconfig.num_train_epochs = 3\n",
    "globalconfig.runs = 1    \n",
    "globalconfig.lr = 1e-4\n",
    "globalconfig.warmup_ratio = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac42efe-13f1-4d52-85e9-d366f3535cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b8786a8-8989-4b1f-af35-82fb728fbb8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T04:31:36.414196Z",
     "iopub.status.busy": "2023-09-13T04:31:36.413348Z",
     "iopub.status.idle": "2023-09-13T04:31:36.447500Z",
     "shell.execute_reply": "2023-09-13T04:31:36.445827Z",
     "shell.execute_reply.started": "2023-09-13T04:31:36.414133Z"
    }
   },
   "outputs": [],
   "source": [
    "# peft_model_id = \"/bime-munin/xiruod/tmp/llama-output/\"\n",
    "peft_model_dir = globalconfig.output_dir\n",
    "\n",
    "config = PeftConfig.from_pretrained(peft_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "625c5741-af07-48da-972b-27f1a60bb006",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T04:31:39.457233Z",
     "iopub.status.busy": "2023-09-13T04:31:39.453160Z",
     "iopub.status.idle": "2023-09-13T04:31:39.470887Z",
     "shell.execute_reply": "2023-09-13T04:31:39.470014Z",
     "shell.execute_reply.started": "2023-09-13T04:31:39.457155Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(peft_type='LORA', auto_mapping=None, base_model_name_or_path='/bime-munin/llama2_hf/llama-2-7b_hf/', revision=None, task_type='SEQ_CLS', inference_mode=True, r=8, target_modules=['q_proj', 'v_proj'], lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', modules_to_save=['classifier'], init_lora_weights=True, layers_to_transform=None, layers_pattern=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "050e07d5-d0e2-4f1e-af34-2fb84873ccf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T04:32:13.116472Z",
     "iopub.status.busy": "2023-09-13T04:32:13.115791Z",
     "iopub.status.idle": "2023-09-13T04:36:17.556432Z",
     "shell.execute_reply": "2023-09-13T04:36:17.555313Z",
     "shell.execute_reply.started": "2023-09-13T04:32:13.116412Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc91313f9a0344b18ef1bf08782d3957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at /bime-munin/llama2_hf/llama-2-7b_hf/ and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = LlamaForSequenceClassification.from_pretrained(config.base_model_name_or_path, return_dict=True, load_in_8bit=globalconfig.quantization, device_map='cuda:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "478e2158-bf27-4d66-ab52-ae6faa6b2d6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T04:36:52.903650Z",
     "iopub.status.busy": "2023-09-13T04:36:52.902995Z",
     "iopub.status.idle": "2023-09-13T04:36:59.932455Z",
     "shell.execute_reply": "2023-09-13T04:36:59.931428Z",
     "shell.execute_reply.started": "2023-09-13T04:36:52.903592Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    }
   ],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "tokenizer.add_special_tokens({\"pad_token\":\"<pad>\"}) \n",
    "\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=128)\n",
    "\n",
    "\n",
    "# Load the Lora model\n",
    "model = PeftModel.from_pretrained(model, peft_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "980ad73f-e77f-4dda-9b9a-2f5f0acd7ddb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T04:43:13.789872Z",
     "iopub.status.busy": "2023-09-13T04:43:13.789120Z",
     "iopub.status.idle": "2023-09-13T04:43:13.808838Z",
     "shell.execute_reply": "2023-09-13T04:43:13.807523Z",
     "shell.execute_reply.started": "2023-09-13T04:43:13.789807Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "ret = tokenizer(['This is a nice day', 'gay is of no use', \"dalits are lowlives\", \"gay is an key participant to our society\"], return_tensors='pt', max_length=globalconfig.max_seq_length, padding='max_length', truncation=True).to(globalconfig.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b832800-996c-458b-8bde-90619558179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = tokenizer(['This is a nice day', 'gay is of no use', \"dalits are lowlives\", \"gay is an key participant to our society\"], return_tensors='pt', max_length=globalconfig.max_seq_length, padding='max_length', truncation=True).to(globalconfig.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "57b008f9-317e-4b6f-9465-73d8302c2131",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T05:15:22.167774Z",
     "iopub.status.busy": "2023-09-13T05:15:22.167055Z",
     "iopub.status.idle": "2023-09-13T05:15:23.672038Z",
     "shell.execute_reply": "2023-09-13T05:15:23.670984Z",
     "shell.execute_reply.started": "2023-09-13T05:15:22.167713Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "rst = model(**ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "95fcc13f-ea7a-4d92-843d-6dca93bb65c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T05:25:54.918791Z",
     "iopub.status.busy": "2023-09-13T05:25:54.918070Z",
     "iopub.status.idle": "2023-09-13T05:25:54.926294Z",
     "shell.execute_reply": "2023-09-13T05:25:54.924527Z",
     "shell.execute_reply.started": "2023-09-13T05:25:54.918727Z"
    }
   },
   "outputs": [],
   "source": [
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "77d5a8fc-f332-4810-81d8-b62a96b38c3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T05:25:56.006694Z",
     "iopub.status.busy": "2023-09-13T05:25:56.005996Z",
     "iopub.status.idle": "2023-09-13T05:25:56.014321Z",
     "shell.execute_reply": "2023-09-13T05:25:56.012690Z",
     "shell.execute_reply.started": "2023-09-13T05:25:56.006639Z"
    }
   },
   "outputs": [],
   "source": [
    "softmax = torch.nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c7959332-dd5e-4e01-a47b-9490a6679ce7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T05:25:56.311250Z",
     "iopub.status.busy": "2023-09-13T05:25:56.310600Z",
     "iopub.status.idle": "2023-09-13T05:25:56.319964Z",
     "shell.execute_reply": "2023-09-13T05:25:56.318180Z",
     "shell.execute_reply.started": "2023-09-13T05:25:56.311190Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp = softmax(rst['logits'].detach().cpu().type(torch.float)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bfb58e0f-f649-4792-ba7c-c16e75c47640",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T05:25:56.944978Z",
     "iopub.status.busy": "2023-09-13T05:25:56.944180Z",
     "iopub.status.idle": "2023-09-13T05:25:56.955546Z",
     "shell.execute_reply": "2023-09-13T05:25:56.953927Z",
     "shell.execute_reply.started": "2023-09-13T05:25:56.944916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9919185 , 0.00808154],\n",
       "       [0.00288396, 0.9971161 ],\n",
       "       [0.00100834, 0.99899167],\n",
       "       [0.98497075, 0.0150292 ]], dtype=float32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fab53c3e-836c-4599-912e-b036a5457a9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T05:26:10.108663Z",
     "iopub.status.busy": "2023-09-13T05:26:10.108019Z",
     "iopub.status.idle": "2023-09-13T05:26:10.115871Z",
     "shell.execute_reply": "2023-09-13T05:26:10.114090Z",
     "shell.execute_reply.started": "2023-09-13T05:26:10.108604Z"
    }
   },
   "outputs": [],
   "source": [
    "y.append(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f03fb6ca-9db5-4e3e-86c8-bf6512819e04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T05:26:10.783721Z",
     "iopub.status.busy": "2023-09-13T05:26:10.783071Z",
     "iopub.status.idle": "2023-09-13T05:26:10.791388Z",
     "shell.execute_reply": "2023-09-13T05:26:10.789626Z",
     "shell.execute_reply.started": "2023-09-13T05:26:10.783661Z"
    }
   },
   "outputs": [],
   "source": [
    "y = np.concatenate(y).astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e1947dea-bb6f-491c-b1c4-29dd1ad99dc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T05:26:12.864460Z",
     "iopub.status.busy": "2023-09-13T05:26:12.863792Z",
     "iopub.status.idle": "2023-09-13T05:26:12.875421Z",
     "shell.execute_reply": "2023-09-13T05:26:12.873978Z",
     "shell.execute_reply.started": "2023-09-13T05:26:12.864400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9919185 , 0.00808154],\n",
       "       [0.00288396, 0.99711609],\n",
       "       [0.00100834, 0.99899167],\n",
       "       [0.98497075, 0.0150292 ],\n",
       "       [0.9919185 , 0.00808154],\n",
       "       [0.00288396, 0.99711609],\n",
       "       [0.00100834, 0.99899167],\n",
       "       [0.98497075, 0.0150292 ],\n",
       "       [0.9919185 , 0.00808154],\n",
       "       [0.00288396, 0.99711609],\n",
       "       [0.00100834, 0.99899167],\n",
       "       [0.98497075, 0.0150292 ]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c51080-041f-4746-8d59-b0ed5c21810e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "82e69b12-f977-49d5-8e8e-bdcca480194b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T05:10:40.128824Z",
     "iopub.status.busy": "2023-09-13T05:10:40.128121Z",
     "iopub.status.idle": "2023-09-13T05:10:40.140396Z",
     "shell.execute_reply": "2023-09-13T05:10:40.139014Z",
     "shell.execute_reply.started": "2023-09-13T05:10:40.128762Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    # tokenize\n",
    "    ret = tokenizer(examples['text'], return_tensors='pt', max_length=globalconfig.max_seq_length, padding='max_length', truncation=True).to(globalconfig.device)\n",
    "\n",
    "    return  ret\n",
    "\n",
    "def datasets_loader(df):\n",
    "    # from pandas df to Dataset & tokenize\n",
    "    # ret_datasets = datasets.Dataset.from_pandas(df[['text','dfSource','label_binary']].rename(columns={\"label_binary\":\"label\"}).reset_index(drop=True))\n",
    "    ret_datasets = datasets.Dataset.from_pandas(df)\n",
    "\n",
    "    ret_tokenized = ret_datasets.map(preprocess_function, batched=True)\n",
    "\n",
    "    return ret_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "69fb52e1-ae36-424c-8d3e-4fcf2c1dac1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T05:10:40.535850Z",
     "iopub.status.busy": "2023-09-13T05:10:40.535392Z",
     "iopub.status.idle": "2023-09-13T05:10:40.541173Z",
     "shell.execute_reply": "2023-09-13T05:10:40.540164Z",
     "shell.execute_reply.started": "2023-09-13T05:10:40.535820Z"
    }
   },
   "outputs": [],
   "source": [
    "test = ['This is a nice day', 'gay is of no use', \"dalits are lowlives\", \"gay is an key participant to our society\"] * 100\n",
    "test_id = [0,1,1,1] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "12538bdb-053d-4b35-9f69-0c5460b2e387",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T05:10:40.870306Z",
     "iopub.status.busy": "2023-09-13T05:10:40.869607Z",
     "iopub.status.idle": "2023-09-13T05:10:40.884972Z",
     "shell.execute_reply": "2023-09-13T05:10:40.883603Z",
     "shell.execute_reply.started": "2023-09-13T05:10:40.870245Z"
    }
   },
   "outputs": [],
   "source": [
    "ret_datasets = datasets.Dataset.from_pandas(pd.DataFrame({\"text\":test, \"label\":test_id}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1a16cbc5-310a-42e5-bf33-607cd99a6614",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T05:10:42.802460Z",
     "iopub.status.busy": "2023-09-13T05:10:42.801748Z",
     "iopub.status.idle": "2023-09-13T05:10:43.093269Z",
     "shell.execute_reply": "2023-09-13T05:10:43.092299Z",
     "shell.execute_reply.started": "2023-09-13T05:10:42.802399Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a46be14536fa47bbb4f62848708f22f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_test = datasets_loader(pd.DataFrame({\"text\":test}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fa57ee-26db-4041-b231-01b7a354d2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
